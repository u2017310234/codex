#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¸‰å±‚ Agent æ¶æ„ - å€Ÿé‰´å›¾ä¸­è®¾è®¡
å°†æå–è¿‡ç¨‹åˆ†ä¸ºï¼šç»“æ„åˆ†æ â†’ æ•°æ®æå– â†’ è¯­ä¹‰ç”Ÿæˆ
"""

from typing import Dict, Any, List
import json
from pathlib import Path


class TableAnalyzerAgent:
    """
    Agent 1: è¡¨æ ¼ç»“æ„åˆ†æå™¨
    
    èŒè´£ï¼š
    - è¯†åˆ«è¡¨æ ¼ç±»å‹ï¼ˆæ•°æ®è¡¨ã€è®¡ç®—è¡¨ã€æŠ¥å‘Šæ¨¡æ¿ï¼‰
    - åˆ†æè¡¨æ ¼å¸ƒå±€ï¼ˆæ ‡é¢˜åŒºã€è¾“å…¥åŒºã€è®¡ç®—åŒºã€è¾“å‡ºåŒºï¼‰
    - æ£€æµ‹æ•°æ®æµå‘
    """
    
    def analyze(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†æè¡¨æ ¼ç»“æ„"""
        print("ğŸ” Agent 1: åˆ†æè¡¨æ ¼ç»“æ„...")
        
        # è¯†åˆ«åŒºåŸŸç±»å‹
        regions = self._identify_regions(context)
        
        # åˆ†ææ•°æ®æµ
        data_flow = self._analyze_data_flow(context)
        
        # è¯†åˆ«è¡¨æ ¼ç±»å‹
        table_type = self._classify_table_type(context)
        
        return {
            "table_type": table_type,  # "financial_model", "data_report", "calculation_sheet"
            "regions": regions,
            "data_flow": data_flow,
            "layout_pattern": self._detect_layout_pattern(context),
        }
    
    def _identify_regions(self, context: Dict) -> List[Dict]:
        """è¯†åˆ«è¡¨æ ¼åŒºåŸŸ"""
        formulas = context.get('cell_formulas', {})
        cell_values = context.get('cell_values', {})
        
        regions = []
        
        # è¾“å…¥åŒºï¼šæ²¡æœ‰å…¬å¼çš„æ•°å€¼å•å…ƒæ ¼
        input_cells = [
            cell for cell, info in cell_values.items()
            if info['is_input'] and info['type'] == 'number'
        ]
        
        if input_cells:
            regions.append({
                "type": "input",
                "description": "è¾“å…¥å‚æ•°åŒº",
                "cells": input_cells[:10],  # ç¤ºä¾‹
                "characteristics": "åŒ…å«ç”¨æˆ·å¯ä¿®æ”¹çš„åŸå§‹æ•°æ®"
            })
        
        # è®¡ç®—åŒºï¼šæœ‰å…¬å¼çš„å•å…ƒæ ¼
        calc_cells = list(formulas.keys())
        if calc_cells:
            regions.append({
                "type": "calculation",
                "description": "è®¡ç®—é€»è¾‘åŒº",
                "cells": calc_cells[:10],
                "characteristics": "åŒ…å«ä¸šåŠ¡è®¡ç®—å…¬å¼"
            })
        
        # è¾“å‡ºåŒºï¼šè¢«ä¾èµ–å°‘çš„å…¬å¼å•å…ƒæ ¼
        deps = context.get('dependencies', {})
        output_cells = [
            cell for cell in calc_cells
            if len(deps.get(cell, {}).get('depended_by', [])) == 0
        ]
        
        if output_cells:
            regions.append({
                "type": "output",
                "description": "ç»“æœè¾“å‡ºåŒº",
                "cells": output_cells,
                "characteristics": "æœ€ç»ˆè®¡ç®—ç»“æœï¼Œæ— å…¶ä»–å•å…ƒæ ¼ä¾èµ–"
            })
        
        return regions
    
    def _analyze_data_flow(self, context: Dict) -> Dict:
        """åˆ†ææ•°æ®æµå‘"""
        calc_order = context.get('calculation_order', [])
        
        # åˆ†å±‚ï¼šè¾“å…¥ â†’ ä¸­é—´å±‚ â†’ è¾“å‡º
        layers = []
        if len(calc_order) > 0:
            # ç®€åŒ–ï¼šæŒ‰ä¾èµ–æ·±åº¦åˆ†å±‚
            layers = [
                {"level": 0, "description": "æ•°æ®æº", "cells": []},
                {"level": 1, "description": "ä¸€çº§è®¡ç®—", "cells": []},
                {"level": 2, "description": "äºŒçº§è®¡ç®—", "cells": []},
            ]
        
        return {
            "flow_direction": "top_to_bottom",  # æˆ– "left_to_right"
            "layers": layers,
            "critical_path": calc_order[:5] if calc_order else [],
        }
    
    def _classify_table_type(self, context: Dict) -> str:
        """åˆ†ç±»è¡¨æ ¼ç±»å‹"""
        formulas = context.get('cell_formulas', {})
        
        # åŸºäºå‡½æ•°ä½¿ç”¨åˆ¤æ–­
        all_functions = set()
        for formula_info in formulas.values():
            all_functions.update(formula_info.get('used_functions', []))
        
        if any(f in all_functions for f in ['NORMSDIST', 'LN', 'EXP']):
            return "financial_model"  # é‡‘èæ¨¡å‹
        elif any(f in all_functions for f in ['VLOOKUP', 'INDEX', 'MATCH']):
            return "data_lookup_table"  # æŸ¥æ‰¾è¡¨
        elif any(f in all_functions for f in ['SUM', 'AVERAGE', 'COUNT']):
            return "summary_report"  # æ±‡æ€»æŠ¥è¡¨
        else:
            return "general_calculation"  # é€šç”¨è®¡ç®—è¡¨
    
    def _detect_layout_pattern(self, context: Dict) -> str:
        """æ£€æµ‹å¸ƒå±€æ¨¡å¼"""
        # ç®€åŒ–ï¼šåŸºäºå•å…ƒæ ¼åˆ†å¸ƒ
        return "vertical_flow"  # æˆ– "horizontal_flow", "matrix"


class DataExtractorAgent:
    """
    Agent 2: æ•°æ®ç»“æ„åŒ–æå–å™¨
    
    èŒè´£ï¼š
    - å°†åŸå§‹æ•°æ®è½¬ä¸ºç»“æ„åŒ– JSON
    - æ ‡æ³¨æ¯ä¸ªå­—æ®µçš„è¯­ä¹‰
    - æå–å…³é”®ä¸šåŠ¡å®ä½“
    """
    
    def extract(self, context: Dict[str, Any], 
                structure_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """æå–ç»“æ„åŒ–æ•°æ®"""
        print("ğŸ“Š Agent 2: æå–ç»“æ„åŒ–æ•°æ®...")
        
        # æå–ä¸šåŠ¡å®ä½“
        entities = self._extract_entities(context, structure_analysis)
        
        # ç»“æ„åŒ–å…¬å¼
        structured_formulas = self._structure_formulas(context)
        
        # æå–å‚æ•°å®šä¹‰
        parameters = self._extract_parameters(context, structure_analysis)
        
        return {
            "entities": entities,
            "formulas": structured_formulas,
            "parameters": parameters,
            "relationships": self._extract_relationships(context),
        }
    
    def _extract_entities(self, context: Dict, analysis: Dict) -> List[Dict]:
        """æå–ä¸šåŠ¡å®ä½“"""
        entities = []
        
        table_type = analysis.get('table_type')
        
        if table_type == 'financial_model':
            # è¯†åˆ«é‡‘èæ¨¡å‹å®ä½“
            entities.append({
                "name": "OptionPricing",
                "type": "FinancialModel",
                "description": "æœŸæƒå®šä»·æ¨¡å‹",
                "attributes": ["spot_price", "strike_price", "volatility", "time_to_maturity"]
            })
        
        return entities
    
    def _structure_formulas(self, context: Dict) -> List[Dict]:
        """ç»“æ„åŒ–å…¬å¼ï¼ˆå¸¦è¯­ä¹‰æ ‡ç­¾ï¼‰"""
        formulas = context.get('cell_formulas', {})
        structured = []
        
        for cell_ref, formula_info in formulas.items():
            structured.append({
                "cell": cell_ref,
                "raw_formula": formula_info['raw_formula'],
                "semantic_type": self._infer_formula_type(formula_info),  # â­ å…³é”®
                "business_meaning": self._guess_business_meaning(formula_info),  # â­ å…³é”®
                "dependencies": formula_info['depends_on'],
                "complexity": formula_info['complexity'],
            })
        
        return structured
    
    def _infer_formula_type(self, formula_info: Dict) -> str:
        """æ¨æ–­å…¬å¼ç±»å‹"""
        functions = formula_info.get('used_functions', [])
        
        if 'NORMSDIST' in functions or 'NORMINV' in functions:
            return "probability_calculation"
        elif 'LN' in functions and 'EXP' in functions:
            return "exponential_growth"
        elif 'SQRT' in functions and 'STDEV' in functions:
            return "volatility_calculation"
        elif 'SUM' in functions or 'AVERAGE' in functions:
            return "aggregation"
        else:
            return "arithmetic"
    
    def _guess_business_meaning(self, formula_info: Dict) -> str:
        """çŒœæµ‹ä¸šåŠ¡å«ä¹‰"""
        formula = formula_info.get('raw_formula', '')
        functions = formula_info.get('used_functions', [])
        
        # åŸºäºæ¨¡å¼åŒ¹é…
        if 'LN' in functions and 'SQRT' in functions:
            return "å¯èƒ½æ˜¯ Black-Scholes d1/d2 å‚æ•°è®¡ç®—"
        elif 'STDEV' in functions and 'SQRT' in functions:
            return "å¹´åŒ–æ³¢åŠ¨ç‡è®¡ç®—"
        elif 'NORMSDIST' in functions:
            return "ç´¯ç§¯æ¦‚ç‡åˆ†å¸ƒè®¡ç®—"
        else:
            return "é€šç”¨è®¡ç®—"
    
    def _extract_parameters(self, context: Dict, analysis: Dict) -> List[Dict]:
        """æå–å‚æ•°å®šä¹‰"""
        parameters = []
        
        # ä»è¾“å…¥åŒºæå–å‚æ•°
        regions = analysis.get('regions', [])
        input_region = next((r for r in regions if r['type'] == 'input'), None)
        
        if input_region:
            for cell in input_region['cells'][:5]:
                cell_info = context['cell_values'].get(cell, {})
                parameters.append({
                    "cell": cell,
                    "value": cell_info.get('value'),
                    "type": cell_info.get('type'),
                    "inferred_name": self._infer_parameter_name(cell),  # â­ æ¨æµ‹å˜é‡å
                })
        
        return parameters
    
    def _infer_parameter_name(self, cell_ref: str) -> str:
        """æ¨æµ‹å‚æ•°åç§°ï¼ˆæœªæ¥å¯ç”¨ LLM å¢å¼ºï¼‰"""
        # ç®€åŒ–ç‰ˆï¼šåŸºäºä½ç½®
        mapping = {
            'B3': 'parameter_1',
            'B4': 'parameter_2',
            'I15': 'time_to_maturity',
            'I19': 'risk_free_rate',
        }
        return mapping.get(cell_ref, f'param_{cell_ref}')
    
    def _extract_relationships(self, context: Dict) -> List[Dict]:
        """æå–å®ä½“å…³ç³»"""
        deps = context.get('dependencies', {})
        relationships = []
        
        for cell, dep_info in list(deps.items())[:5]:
            for depends_on in dep_info.get('direct_depends', []):
                relationships.append({
                    "from": depends_on,
                    "to": cell,
                    "type": "calculates",
                })
        
        return relationships


class InsightGeneratorAgent:
    """
    Agent 3: æ´å¯Ÿç”Ÿæˆå™¨
    
    èŒè´£ï¼š
    - ç”¨è‡ªç„¶è¯­è¨€æè¿°ä¸šåŠ¡é€»è¾‘
    - ç”Ÿæˆæ•°æ®åˆ†ææ´å¯Ÿ
    - æä¾›ä¼˜åŒ–å»ºè®®
    """
    
    def generate(self, context: Dict[str, Any], 
                 structure: Dict[str, Any], 
                 data: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆè¯­ä¹‰åŒ–æ´å¯Ÿ"""
        print("ğŸ’¡ Agent 3: ç”Ÿæˆä¸šåŠ¡æ´å¯Ÿ...")
        
        # ç”Ÿæˆè‡ªç„¶è¯­è¨€æè¿°
        nl_description = self._generate_description(context, structure, data)
        
        # åˆ†ææ´å¯Ÿ
        insights = self._generate_insights(data)
        
        # ä¼˜åŒ–å»ºè®®
        suggestions = self._generate_suggestions(context, data)
        
        return {
            "natural_language_description": nl_description,
            "insights": insights,
            "suggestions": suggestions,
            "summary": self._generate_summary(context, structure, data),
        }
    
    def _generate_description(self, context: Dict, structure: Dict, data: Dict) -> str:
        """ç”Ÿæˆè‡ªç„¶è¯­è¨€æè¿°"""
        table_type = structure.get('table_type', 'unknown')
        formulas_count = len(context.get('cell_formulas', {}))
        
        desc_parts = []
        
        # è¡¨æ ¼ç±»å‹æè¿°
        type_desc = {
            'financial_model': 'è¿™æ˜¯ä¸€ä¸ªé‡‘èå®šä»·æ¨¡å‹',
            'data_lookup_table': 'è¿™æ˜¯ä¸€ä¸ªæ•°æ®æŸ¥æ‰¾è¡¨',
            'summary_report': 'è¿™æ˜¯ä¸€ä¸ªæ•°æ®æ±‡æ€»æŠ¥è¡¨',
            'general_calculation': 'è¿™æ˜¯ä¸€ä¸ªé€šç”¨è®¡ç®—è¡¨æ ¼',
        }
        desc_parts.append(type_desc.get(table_type, 'è¿™æ˜¯ä¸€ä¸ª Excel è¡¨æ ¼'))
        
        # å¤æ‚åº¦æè¿°
        if formulas_count > 20:
            desc_parts.append(f"åŒ…å« {formulas_count} ä¸ªè®¡ç®—å…¬å¼ï¼Œé€»è¾‘è¾ƒä¸ºå¤æ‚")
        elif formulas_count > 5:
            desc_parts.append(f"åŒ…å« {formulas_count} ä¸ªè®¡ç®—å…¬å¼ï¼Œé€»è¾‘ä¸­ç­‰å¤æ‚åº¦")
        else:
            desc_parts.append(f"åŒ…å« {formulas_count} ä¸ªç®€å•è®¡ç®—å…¬å¼")
        
        # ä¸šåŠ¡é€»è¾‘æè¿°
        entities = data.get('entities', [])
        if entities:
            entity_names = [e['description'] for e in entities]
            desc_parts.append(f"ä¸»è¦æ¶‰åŠï¼š{', '.join(entity_names)}")
        
        return 'ã€‚'.join(desc_parts) + 'ã€‚'
    
    def _generate_insights(self, data: Dict) -> List[str]:
        """ç”Ÿæˆæ•°æ®æ´å¯Ÿ"""
        insights = []
        
        formulas = data.get('formulas', [])
        
        # ç»Ÿè®¡å…¬å¼ç±»å‹
        types_count = {}
        for f in formulas:
            semantic_type = f.get('semantic_type', 'unknown')
            types_count[semantic_type] = types_count.get(semantic_type, 0) + 1
        
        if types_count.get('probability_calculation', 0) > 0:
            insights.append("âœ… æ£€æµ‹åˆ°æ¦‚ç‡è®¡ç®—ï¼Œå¯èƒ½ç”¨äºé£é™©è¯„ä¼°æˆ–æœŸæƒå®šä»·")
        
        if types_count.get('volatility_calculation', 0) > 0:
            insights.append("âœ… æ£€æµ‹åˆ°æ³¢åŠ¨ç‡è®¡ç®—ï¼Œè¿™æ˜¯é‡‘èé£é™©åº¦é‡çš„æ ¸å¿ƒæŒ‡æ ‡")
        
        # å¤æ‚åº¦æ´å¯Ÿ
        complex_formulas = [f for f in formulas if f.get('complexity') == 'high']
        if complex_formulas:
            insights.append(f"âš ï¸  æœ‰ {len(complex_formulas)} ä¸ªé«˜å¤æ‚åº¦å…¬å¼ï¼Œè½¬æ¢æ—¶éœ€ç‰¹åˆ«æ³¨æ„")
        
        return insights
    
    def _generate_suggestions(self, context: Dict, data: Dict) -> List[str]:
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        suggestions = []
        
        patterns = context.get('patterns', [])
        if patterns:
            suggestions.append("ğŸš€ æ£€æµ‹åˆ°é‡å¤æ¨¡å¼ï¼Œå»ºè®®ä½¿ç”¨ Pandas å‘é‡åŒ–æ“ä½œæ›¿ä»£é€è¡Œè®¡ç®—")
        
        vba_exists = context.get('vba_code', {}).get('has_vba', False)
        if vba_exists:
            suggestions.append("ğŸ“Œ åŒ…å« VBA ä»£ç ï¼Œå»ºè®®åˆ†æå…¶ä¸šåŠ¡é€»è¾‘å¹¶æ•´åˆåˆ° Python ç±»ä¸­")
        
        formulas = data.get('formulas', [])
        if len(formulas) > 10:
            suggestions.append("ğŸ’¡ å…¬å¼è¾ƒå¤šï¼Œå»ºè®®æŒ‰ä¸šåŠ¡æ¨¡å—æ‹†åˆ†ä¸ºå¤šä¸ª Python ç±»")
        
        return suggestions
    
    def _generate_summary(self, context: Dict, structure: Dict, data: Dict) -> str:
        """ç”Ÿæˆæ€»ç»“"""
        return f"""
ã€è¡¨æ ¼ç±»å‹ã€‘{structure.get('table_type')}
ã€å…¬å¼æ•°é‡ã€‘{len(context.get('cell_formulas', {}))} ä¸ª
ã€ä¸šåŠ¡å®ä½“ã€‘{len(data.get('entities', []))} ä¸ª
ã€å»ºè®®ã€‘{len(self._generate_suggestions(context, data))} æ¡ä¼˜åŒ–å»ºè®®
        """.strip()


# æ•´åˆä¸‰å±‚ Agent
class EnhancedContextExtractor:
    """å¢å¼ºç‰ˆä¸Šä¸‹æ–‡æå–å™¨ - é›†æˆä¸‰å±‚ Agent"""
    
    def __init__(self, excel_file: str):
        self.excel_file = excel_file
        self.analyzer = TableAnalyzerAgent()
        self.extractor = DataExtractorAgent()
        self.insight_generator = InsightGeneratorAgent()
    
    def extract_all(self) -> Dict[str, Any]:
        """å®Œæ•´æå–æµç¨‹"""
        print("=" * 80)
        print("ğŸš€ ä¸‰å±‚ Agent æå–æµç¨‹")
        print("=" * 80)
        
        # ç¬¬ä¸€æ­¥ï¼šæŠ€æœ¯æå–ï¼ˆåŸæœ‰é€»è¾‘ï¼‰
        from extractors.context_extractor import ExcelContextExtractor
        base_extractor = ExcelContextExtractor(self.excel_file)
        base_context = base_extractor.extract_all()
        
        # ç¬¬äºŒæ­¥ï¼šç»“æ„åˆ†æ
        structure_analysis = self.analyzer.analyze(base_context)
        
        # ç¬¬ä¸‰æ­¥ï¼šæ•°æ®æå–
        structured_data = self.extractor.extract(base_context, structure_analysis)
        
        # ç¬¬å››æ­¥ï¼šæ´å¯Ÿç”Ÿæˆ
        insights = self.insight_generator.generate(
            base_context, 
            structure_analysis, 
            structured_data
        )
        
        # æ•´åˆç»“æœ
        return {
            # åŸå§‹æŠ€æœ¯æ•°æ®
            "raw_context": base_context,
            
            # ç»“æ„åŒ–è¯­ä¹‰æ•°æ®
            "structure_analysis": structure_analysis,
            "structured_data": structured_data,
            "business_insights": insights,
            
            # å…ƒä¿¡æ¯
            "extraction_method": "three_layer_agents",
            "agents_used": ["TableAnalyzer", "DataExtractor", "InsightGenerator"],
        }


def demo():
    """æ¼”ç¤ºä¸‰å±‚ Agent"""
    excel_file = "/workspaces/RM_Tools/Margin Call.xlsm"
    
    extractor = EnhancedContextExtractor(excel_file)
    result = extractor.extract_all()
    
    print("\n" + "=" * 80)
    print("ğŸ“Š æå–ç»“æœæ‘˜è¦")
    print("=" * 80)
    
    # æ˜¾ç¤ºä¸šåŠ¡æ´å¯Ÿ
    insights = result['business_insights']
    print("\nğŸ’¡ ä¸šåŠ¡æ´å¯Ÿ:")
    print(insights['natural_language_description'])
    
    print("\nâœ… å…³é”®å‘ç°:")
    for insight in insights['insights']:
        print(f"  {insight}")
    
    print("\nğŸš€ ä¼˜åŒ–å»ºè®®:")
    for suggestion in insights['suggestions']:
        print(f"  {suggestion}")
    
    # ä¿å­˜ç»“æœ
    output_file = "/workspaces/RM_Tools/excel_to_code/output/contexts/enhanced_context.json"
    Path(output_file).parent.mkdir(parents=True, exist_ok=True)
    with open(output_file, 'w', encoding='utf-8') as f:
        # åªä¿å­˜å¯åºåˆ—åŒ–çš„éƒ¨åˆ†
        json.dump({
            "structure_analysis": result['structure_analysis'],
            "structured_data": result['structured_data'],
            "business_insights": result['business_insights'],
        }, f, indent=2, ensure_ascii=False)
    
    print(f"\nâœ… å¢å¼ºä¸Šä¸‹æ–‡å·²ä¿å­˜: {output_file}")


if __name__ == '__main__':
    demo()
